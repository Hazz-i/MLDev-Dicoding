# -*- coding: utf-8 -*-
"""Book Recommendations System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lbjbwZmCdMcT65qPiB5vP74Vxw8CL7cr
"""

import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

"""## **DATA UNDERSTANDING**"""

books_df = pd.read_csv("./data/books.csv")
ratings_df = pd.read_csv("./data/ratings.csv")
users_df = pd.read_csv("./data/users.csv")

print(f"Jumlah data buku: {books_df.shape[0]}")
print(f"Jumlah data penilaian buku: {ratings_df.shape[0]}")
print(f"Jumlah data pengguna: {users_df.shape[0]}")

"""Meload data yang akan di gunkan, terdapat 3 data yaitu buku, rating, dan users.

## **UNIVARIATE EXPLORATORY DATA ANALYSIS**

### **Buku**
"""

books_df.info()

"""Melhat informasi dari data buku, berdasarkan data tersebut data buku memilki **271.360** data serta memiliki 7 kolom bertipe object."""

unique_books = books_df["Book-Title"].unique()

print(f"Jumlah buku :{len(unique_books)}")
print(f"Jumlah publisher :{len(books_df['Book-Author'].unique())}\n")

print(f"Nama Buku : {unique_books}")

"""Mengetahui total data semua buku dengan filter nama buku yang sama tidak di hiting kembali dengan menggunkan _unique()_. Pada buku ini memiliki total **242.135** data buku dengan judul yang berbeda dan memilki **102.024** data.

### **Users**
"""

users_df.shape

"""Menghtiung jumlah data users. Berdasarkan perhitungan tersebut data users memilki **278.858** baris dan terdapat 3 kolom."""

users_df.head()

"""Menampilkan 5 data pertama pada dataset users.

### **Rating**
"""

ratings_df.head()

"""Menampilkan 5 data teratas dari table ratings."""

ratings_df.describe()

"""Menampilkan statisik deskriptif pada data rating. Berdasarkan perhitungan tersebut data rating memiliki nilai maximal 10 dan minimal 0."""

print('Jumlah userID: ', len(ratingsMenghtiung jumlah data users. Berdasarkan perhitungan tersebut data users memilki **278.858** baris dan terdapat 3 kolom._df["User-ID"].unique()))
print('Jumlah ISBN: ', len(ratings_df["ISBN"].unique()))
print('Jumlah data rating: ', len(ratings_df))

"""Menampilkan jumlah id, ISBN, dan rating yang terdapat pada masing masing dataset.

## **DATA PREPROCESSING**

### **Mengetahui jumlah rating pada tiap buku**
"""

books_with_ratings = ratings_df.merge(books_df, on='ISBN')
books_with_ratings.info()
books_with_ratings.head()

"""Menggabungkan data rating dan data buku dari ISBN menggunakan fungsi merge yang terdapat pada pandas."""

# cek missing value
books_with_ratings.isna().sum()

"""Melihat jumlah nilaii null pada dataset.

### **Menghitung jumlah rating buku**
"""

num_rating_df = books_with_ratings.groupby('Book-Title').count()['Book-Rating'].reset_index()
num_rating_df.rename(columns={'Book-Rating': 'num_ratings'}, inplace=True)
num_rating_df.head()

"""Membuat table yang berisi jumlah nilai rating dan judul buku dengan cara menjumlahkan data rating pada setiap judul buku.

### **Menghitung rata-rata rating buku**
"""

avg_rating_df = books_with_ratings.groupby('Book-Title')['Book-Rating'].mean().reset_index()
avg_rating_df.rename(columns={'Book-Rating': 'avg_rating'}, inplace=True)
avg_rating_df.head()

"""Membuat table yang berisi data judul buku dan rata rata rating.

### **Gabungkan rating dan rata-rata rating buku**
"""

popular_df = num_rating_df.merge(avg_rating_df, on='Book-Title')
popular_df.sample(5)

"""Menggabungkan data table berisi data judl buku, jumlah rating, dan rata rata rating.

### **Melihat rating terbanyak**
"""

popular_df.sort_values('num_ratings', ascending=False).head()

"""### **Melihat 50 buku dengan rating diatas 250 dan urutkan beradasarkan rata rata rating**"""

popular_df = popular_df[popular_df['num_ratings'] >= 250].sort_values('avg_rating', ascending=False).head(50)
popular_df.head()

"""### **Menggabungkan popular_df dengan book_df dan membuang kolom duplikat**"""

popular_df = popular_df.merge(books_df, on='Book-Title').drop_duplicates('Book-Title')[['Book-Title', 'Book-Author', 'Image-URL-M', 'num_ratings', 'avg_rating']]
popular_df.head()

"""### **Melihat gambar buku yang paling populer**"""

popular_df['Image-URL-M'][0]

# mengecek total buku
print(f"Jumlah Buku :{len(popular_df['Book-Title'].unique())}")

# mengecek nama publisher dan author
print(f"judul buku :{popular_df['Book-Title'][:10].tolist()}\n")

print(f"nama author :{popular_df['Book-Author'][:10].tolist()}")

"""## **MODEL DEVELOPMENT - COLLABORATIF FILTERING (item based)**

### **Memilih user yang aktif**
"""

x = books_with_ratings.groupby('User-ID').count()['Book-Rating'] > 200
active_users = x[x].index  # mendapatkan user id-nya
active_users

"""Memilih user yang aktif, dengan cara memfilter user yang sudah memberikan rating pada buku yang ada pada datset dengan jumlah lebih dari 200 rating.

### **Mere-filter data buku dengan user yang aktif**
"""

# filter data buku dengan user yang masih akttif
filtered_rating = books_with_ratings[books_with_ratings['User-ID'].isin(active_users)]
filtered_rating.head()

"""Memperbarui data filtered_rating dengan ketentuan berisi user yang masi aktif.

### **Memilih buku populer**
"""

y = filtered_rating.groupby('Book-Title').count()['Book-Rating'] >= 50
famous_books = y[y].index  # dapatkan judul bukunya
famous_books

"""Memilih buku popular menggunakan banyaknya data user yang telah memberi rating kepada buku dengan memberikan treshold sebanyak 50 rating pada setiap buku yang akan di pilih menjadi buku popular."""

final_ratings = filtered_rating[filtered_rating['Book-Title'].isin(famous_books)]

"""Memfilter data dengan isi data buku yang popular saja.

### **Membuat pivot tabel**
"""

pt = final_ratings.pivot_table(index='Book-Title', columns='User-ID', values='Book-Rating')
pt.fillna(0, inplace=True)  # replace nilai null dengan 0
pt

similarity_scores = cosine_similarity(pt)

"""Menggunakan cosine similarity untuk menghitung tingkat kemiripan antar buku berdasarkan pola rating pengguna."""

def recommend(book_name):
    # Mencari index buku
    index = np.where(pt.index == book_name)[0][0]
    # Mendapatkan 4 buku yang mirip teratas (yang pertama merupakan buku itu sendiri)
    similar_items = sorted(list(enumerate(similarity_scores[index])), key=lambda x: x[1], reverse=True)[1:5]

    data = []
    for i in similar_items:
        item = []
        temp_df = books_df[books_df['Book-Title'] == pt.index[i[0]]]
        item.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Title'].values))
        item.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Author'].values))
        item.extend(list(temp_df.drop_duplicates('Book-Title')['Image-URL-M'].values))

        data.append(item)
    return data

"""Fungsi ini bertujuan memberikan rekomendasi buku berdasarkan kesamaan (similarity) dengan buku yang diberikan (book_name). Fungsi mengembalikan data dari 4 buku paling mirip dengan buku yang diberikan."""

# Mencoba rekomendasi denagan buku yang berjudul Animal Farm
recommend('Animal Farm')

"""## **Export**"""

import pickle
pickle.dump(popular_df, open('popular.pkl', 'wb'))
pickle.dump(pt, open('pt.pkl', 'wb'))
pickle.dump(books, open('books.pkl', 'wb'))
pickle.dump(similarity_scores, open('similarity_scores.pkl', 'wb'))